{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset class for multilabel classification\n",
    "class MultiClassImageDataset(Dataset):\n",
    "    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n",
    "        self.ann_df = ann_df \n",
    "        self.super_map_df = super_map_df\n",
    "        self.sub_map_df = sub_map_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ann_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.ann_df['image'][idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        super_idx = self.ann_df['superclass_index'][idx]\n",
    "        super_label = self.super_map_df['class'][super_idx]\n",
    "        \n",
    "        sub_idx = self.ann_df['subclass_index'][idx]\n",
    "        sub_label = self.sub_map_df['class'][sub_idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)  \n",
    "            \n",
    "        return image, super_idx, super_label, sub_idx, sub_label\n",
    "\n",
    "class MultiClassImageTestDataset(Dataset):\n",
    "    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
    "        self.super_map_df = super_map_df\n",
    "        self.sub_map_df = sub_map_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): # Count files in img_dir\n",
    "        return len([fname for fname in os.listdir(self.img_dir)])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(idx) + '.jpg'\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)  \n",
    "            \n",
    "        return image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "train_ann_df = pd.read_csv('train_data.csv')\n",
    "# test_ann_df = pd.read_csv('test_data.csv')\n",
    "super_map_df = pd.read_csv('superclass_mapping.csv')\n",
    "sub_map_df = pd.read_csv('subclass_mapping.csv')\n",
    "\n",
    "train_img_dir = 'train_images'\n",
    "test_img_dir = 'test_images'\n",
    "\n",
    "\n",
    "# Data Augumentation\n",
    "train_image_processing = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.RandomAffine(degrees=0, shear=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Test transform (no augmentation)\n",
    "test_image_processing = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "#  Improved Dataset Splitting Strategy\n",
    "# pseudo_novel_superclass = 2 \n",
    "# pseudo_novel_subclass = 86\n",
    "\n",
    "# train_mask = ~((train_ann_df['superclass_index'] == pseudo_novel_superclass) |\n",
    "#                (train_ann_df['subclass_index'] == pseudo_novel_subclass))\n",
    "\n",
    "# val_mask = ((train_ann_df['superclass_index'] == pseudo_novel_superclass) |\n",
    "#             (train_ann_df['subclass_index'] == pseudo_novel_subclass))\n",
    "\n",
    "# train_subset_df = train_ann_df[train_mask].reset_index(drop=True)\n",
    "# val_subset_df = train_ann_df[val_mask].reset_index(drop=True)\n",
    "\n",
    "# Rebuild datasets\n",
    "# train_dataset = MultiClassImageDataset(train_subset_df, super_map_df, sub_map_df, train_img_dir, transform=train_image_processing)\n",
    "# val_dataset = MultiClassImageDataset(val_subset_df, super_map_df, sub_map_df, train_img_dir, transform=test_image_processing)\n",
    "\n",
    "# Dataloaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Create train and val split\n",
    "train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=train_image_processing)\n",
    "train_dataset, val_dataset = random_split(train_dataset, [0.9, 0.1]) \n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=test_image_processing)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=1, \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_novel_class(logits, threshold=1.0, novel_index=3):\n",
    "    energy = torch.logsumexp(logits, dim=1)\n",
    "    _, predicted_labels = torch.max(logits, dim=1)\n",
    "    predicted_labels[energy < threshold] = novel_index\n",
    "    return predicted_labels\n",
    "# def detect_novel_class_with_softmax(logits, threshold=0.4, novel_index=3):\n",
    "#     probs = F.softmax(logits, dim=1)\n",
    "#     max_probs, predicted_labels = torch.max(probs, dim=1)\n",
    "#     predicted_labels[max_probs < threshold] = novel_index\n",
    "#     return predicted_labels\n",
    "# def detect_novel_class_combined(logits, energy_threshold=2.5, prob_threshold=0.4, novel_index=3):\n",
    "#     energy = torch.logsumexp(logits, dim=1)\n",
    "#     probs = F.softmax(logits, dim=1)\n",
    "#     max_probs, predicted_labels = torch.max(probs, dim=1)\n",
    "#     novel_flags = (energy < energy_threshold) | (max_probs < prob_threshold)\n",
    "#     predicted_labels[novel_flags] = novel_index\n",
    "#     return predicted_labels\n",
    "# def detect_novel_class_entropy(logits, energy_threshold=2.5, entropy_threshold=1.8, novel_index=3):\n",
    "#     energy = torch.logsumexp(logits, dim=1)\n",
    "#     probs = F.softmax(logits, dim=1)\n",
    "#     entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1)\n",
    "    \n",
    "#     _, predicted_labels = torch.max(logits, dim=1)\n",
    "#     novel_flags = (energy < energy_threshold) | (entropy > entropy_threshold)\n",
    "#     predicted_labels[novel_flags] = novel_index\n",
    "#     return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_energy_threshold(model, val_loader, min_t=0.5, max_t=3.0, step=0.1, device=\"cpu\"):\n",
    "    best_threshold_super = 1.5\n",
    "    best_threshold_sub = 2.0\n",
    "    best_unseen_acc = 0.0\n",
    "\n",
    "    # Simulate unseen samples in validation set\n",
    "    for t_super in np.arange(min_t, max_t, step):\n",
    "        for t_sub in np.arange(min_t, max_t, step):\n",
    "            unseen_correct = 0\n",
    "            unseen_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, super_labels, sub_labels in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    super_labels = super_labels.to(device)\n",
    "                    sub_labels = sub_labels.to(device)\n",
    "\n",
    "                    super_logits, sub_logits = model(images)\n",
    "\n",
    "                    super_preds = detect_novel_class(super_logits, threshold=t_super, novel_index=3)\n",
    "                    sub_preds = detect_novel_class(sub_logits, threshold=t_sub, novel_index=87)\n",
    "\n",
    "                    unseen_mask = super_labels == 3  # ground truth novel superclass\n",
    "                    unseen_correct += (super_preds[unseen_mask] == super_labels[unseen_mask]).sum().item()\n",
    "                    unseen_total += unseen_mask.sum().item()\n",
    "\n",
    "            if unseen_total > 0:\n",
    "                acc = 100 * unseen_correct / unseen_total\n",
    "                if acc > best_unseen_acc:\n",
    "                    best_unseen_acc = acc\n",
    "                    best_threshold_super = t_super\n",
    "                    best_threshold_sub = t_sub\n",
    "\n",
    "    print(f\"Best thresholds found: super={best_threshold_super:.2f}, sub={best_threshold_sub:.2f}\")\n",
    "    return best_threshold_super, best_threshold_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bindumadhavi/Documents/Projects/nndl_project/nndl/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import CLIPVisionModel, CLIPImageProcessor\n",
    "\n",
    "class CLIPAdapterModel(nn.Module):\n",
    "    def __init__(self, num_super=4, num_sub=88):\n",
    "        super(CLIPAdapterModel, self).__init__()\n",
    "        \n",
    "        self.clip = CLIPVisionModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        self.processor = CLIPImageProcessor()\n",
    "\n",
    "        for param in self.clip.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        clip_dim = self.clip.config.hidden_size\n",
    "\n",
    "        self.super_head = nn.Sequential(\n",
    "            nn.Linear(clip_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256, num_super)\n",
    "        )\n",
    "\n",
    "        self.sub_head = nn.Sequential(\n",
    "            nn.Linear(clip_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512, num_sub)\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.clip(pixel_values=pixel_values)\n",
    "        features = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        super_logits = self.super_head(features)\n",
    "        sub_logits = self.sub_head(features)\n",
    "\n",
    "        return super_logits, sub_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPTrainer:\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def train_epoch(self):\n",
    "        running_loss = 0.0\n",
    "            \n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            images, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            super_outputs, sub_outputs = self.model(images)\n",
    "            loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Loss: {running_loss / len(self.train_loader):.4f}\")\n",
    "\n",
    "    def validate_epoch(self, energy_threshold_super=1.5, energy_threshold_sub=2.0):\n",
    "        super_correct = 0\n",
    "        sub_correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.val_loader):\n",
    "                images, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
    "\n",
    "                super_outputs, sub_outputs = self.model(images)\n",
    "\n",
    "                loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n",
    "                super_preds = detect_novel_class(super_outputs, energy_threshold_super, novel_index=3)\n",
    "                sub_preds = detect_novel_class(sub_outputs, energy_threshold_sub, novel_index=87)\n",
    "\n",
    "                total += super_labels.size(0)\n",
    "                super_correct += (super_preds == super_labels).sum().item()\n",
    "                sub_correct += (sub_preds == sub_labels).sum().item()\n",
    "                running_loss += loss.item()  \n",
    "\n",
    "        print(f'Validation loss: {running_loss/i:.3f}')\n",
    "        print(f\"Val Superclass Acc: {100 * super_correct / total:.2f}%\")\n",
    "        print(f\"Val Subclass Acc: {100 * sub_correct / total:.2f}%\")\n",
    "\n",
    "    def test(self, save_to_csv=True, return_predictions=False, energy_threshold_super=1.2, energy_threshold_sub=1.3):\n",
    "        if not self.test_loader:\n",
    "            raise NotImplementedError('test_loader not specified')\n",
    "\n",
    "        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n",
    "        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.test_loader):\n",
    "                images, img_names = data[0].to(self.device), data[1]\n",
    "                super_outputs, sub_outputs = self.model(images)\n",
    "\n",
    "                super_preds = detect_novel_class(super_outputs, energy_threshold_super, novel_index=3)\n",
    "                sub_preds = detect_novel_class(sub_outputs, energy_threshold_sub, novel_index=87)\n",
    "\n",
    "                test_predictions['image'].append(img_names[0])\n",
    "                test_predictions['superclass_index'].append(super_preds.item())\n",
    "                test_predictions['subclass_index'].append(sub_preds.item())\n",
    "\n",
    "        test_predictions = pd.DataFrame(data=test_predictions)\n",
    "        if save_to_csv:\n",
    "            test_predictions.to_csv('example_test_predictions.csv', index=False)\n",
    "        if return_predictions:\n",
    "            return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "# Init model and trainer\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--device', default='cpu', help=\"Device to run on: 'cpu' or 'cuda'\")\n",
    "# args = parser.parse_args()\n",
    "# device = args.device\n",
    "\n",
    "# print(\"----device------\", device)\n",
    "\n",
    "device = \"cpu\"\n",
    "model = CLIPAdapterModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "trainer = CLIPTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogitAdjustmentLoss(torch.nn.Module):\n",
    "    def __init__(self, prior):\n",
    "        super().__init__()\n",
    "        self.register_buffer('prior', torch.tensor(prior).log())\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        adjusted_logits = logits + self.prior.unsqueeze(0)\n",
    "        return F.cross_entropy(adjusted_logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAALWpJREFUeJzt3QmcjWX/x/EfxsxYR4ghyyhb1iIkWiwZTB5LPUliknYqVCJtomaibGXpKQ0eRQgtQiUUUaGQapJdY4vszdju/+t39ZzznzP7jDNzznXm83697mbOfe5zn+tcHed859ruAo7jOAIAAGChgr4uAAAAQE4RZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAPitnTt3SoECBWTatGnufS+88ILZlxduuukms7msWLHCPPe8efPy5PnvvvtuiYiIyJPnAmxFkAH8hH5Z65dketvatWt9XURrJSQkmAD0448/ir/x57IBNgjydQEAeHrxxRelWrVqqfZXr17dJ+XxN88884wMGTIk22Fh+PDhpnXjqquuyvLjPvvsM8ltGZXtrbfekgsXLuR6GQCbEWQAP9OhQwe55pprfF0MOXXqlBQrVkz8TVBQkNly0+nTp6Vo0aISHBwsvlS4cGGfPj9gA7qWAEvHjbz66qvyn//8R6644goJCQmRJk2ayPfff5/q+F9//VVuu+02KV26tISGhpqQ9NFHH6XZrbVy5Up5+OGHpVy5clKpUiX3/RMnTpTLL79cihQpIk2bNpWvv/7aY/zIyZMnTeh57LHHUj3/3r17pVChQhITE5Ph6zp69KgZExIWFialSpWS6Ohosy+ltMbIfP7559KyZUvzuOLFi0utWrXk6aefdo9r0bpRffr0cXfVucbd6GuoV6+erF+/Xm644QYTYFyPTTlGxuX8+fPmmPDwcPO6//Wvf8mePXs8jtEWFn09KSU/Z2ZlS2uMjAbMxx9/XCpXrmz+v+tr1feC4zgex+l5+vfvLwsXLjSvT4+tW7euLFmyJMP/D4BtaJEB/MyxY8fkzz//TPWlVKZMGY997733npw4cUIeeOABc/+oUaOkW7dusn37dvdf8lu2bJEWLVrIZZddZrpj9Et3zpw50qVLF/nggw+ka9euHufUEHPppZfKc889Z74w1eTJk80X4vXXXy8DBw40QUoff8kll7jDjoYHPdf7778vY8aMMcHFZdasWeZLtmfPnum+Zr2/c+fOsmrVKnnwwQflyiuvlAULFpgwkxl9jbfccos0aNDAdMvpF/bvv/8uq1evNvfruXS/vqb777/fvA513XXXuc9x+PBh0xJ2xx13yF133SXly5fP8DlfeuklU+dPPfWUHDx4UMaNGydt27Y141w07GVVVsqWsp40NC1fvlz69u1ruqKWLl0qTz75pPzxxx8yduxYj+O1PufPn2/+v5YoUUImTJggt956q+zevTvV+wmwlgPAL8TFxemf1GluISEh7uN27Nhh9pUpU8Y5cuSIe/+HH35o9n/88cfufW3atHHq16/vJCYmuvdduHDBue6665waNWqkeu6WLVs6586dc+9PSkoyz9OkSRPn7Nmz7v3Tpk0zx994443ufUuXLjX7Fi9e7PG6GjRo4HFcWhYuXGgeO2rUKPc+Lcf1119v9mv5XJ5//nmzz2Xs2LHm9qFDh9I9//fff5/qPC5aNr1vypQpad6XvOzLly83x1522WXO8ePH3fvnzJlj9o8fP969r2rVqk50dHSm58yobPp4PU/Keho5cqTHcbfddptToEAB5/fff3fv0+OCg4M99m3cuNHsf/3119OpKcA+dC0Bfka7cbSrJPm2ePHiVMd1797dtIq4uP6a1xYZdeTIEfnyyy/l9ttvNy032sqjm7Y+REZGytatW81f8cndd999Hq0p69atM8fr/uTjUrR1JflzK22RqFixorz77rvufT/99JNs2rTJtHJk5NNPPzXnf+ihh9z7tByPPPJIpvWl3Unqww8/zPHAWG3F0a6drOrdu7dp4XDRrrsKFSqY15Gb9PxaL48++qjHfu1q0uyS8n2i/0+069FFW61Klizpfo8AgYCuJcDP6BiUrAz2rVKlisdtV7D466+/zE/tXtEvt2effdZsadFuEe12ckk5W2rXrl1pzpjS0JFy7EbBggVNwNGuKNdgWQ01Oi7n3//+d4avRZ9Hg4B2USWn4z8yo4Hu7bfflnvvvdd0n7Vp08Z0sWm40DJlhdZBdgb21qhRw+O2djNpHWm3W27SetKwmDxEubqoXPdn9B5xvU9c7xEgEBBkAEslbzlJzjXo09U68cQTT5gWmLSkDCjZGd+RXkvF6NGjzQDTHj16mHE8On5FB/DmFi3zV199ZcaNLFq0yAxm1bE6rVu3NtOn06unlOfwtvQW7dOBwlkpU168R4BAQNcSEKB0lpHSgb/axZDWlvIv+5SqVq3qbt1J7ty5c2m2PujsmKuvvtq0xOjMJh1U2qtXr0zLqs+zb98+M/spufj4+Cy9Vm150ZYYHWj8888/m8G42q2m4UZ5eyVg7ZZLGQy0jpK3UmnLR1qzrlK2mmSnbFpPuu6MdhWmnJnmuh/IbwgyQIDSKdQ6zffNN980ISGlQ4cOZXoO7eLS2S26MJuGFxcNKul1T2hw0ZYQncmjj9XZQJnp2LGjOb92SyVvuXj99dczfayOBUrJtbBcUlKS+elaDyetYJETM2bM8AgTeskCrePkr1XHpuhqzGfOnHHv++STT1JN085O2bSetF7eeOMNj/06W0kDUVbqGgg0dC0BfkYHbLr+wk5Op+S6WlmyM3BY11epX7++GbCrjz9w4ICsWbPGrO+ycePGDB+v40Z03RYddKtdNTpwWFtidJ0T/aJOqzXhzjvvlMGDB5vp0zp4NyuLunXq1MlME9cxLnr+OnXqmGnDOhU9Mzp9WbuWoqKiTIuEjvuZNGmSmRqur11pWXVQ8JQpU0wrlIaHZs2apbmCclbomjx6bh0grPWpoU276bSOXXTMjgac9u3bm3rbtm2bzJw502PwbXbLpvXUqlUrGTZsmKmnhg0bmtCoA50HDBiQ6txAvuDraVMAMp9+nXx6rmv69ejRo1OdQ/fr9OTktm3b5vTu3dsJDw93ChcubKYO33LLLc68efNSPbdOBU7LhAkTzDRgnQbetGlTZ/Xq1U7jxo2d9u3bp3l8x44dzfm++eabLL/+w4cPO7169XJKlizphIWFmd9/+OGHTKdfL1u2zOncubNTsWJFM91Yf/bo0cP57bffPM6v09Pr1KnjBAUFeZxTp0LXrVs3zTKlN/161qxZztChQ51y5co5RYoUcaKiopxdu3alevxrr71m6lvrrUWLFs66detSnTOjsqWcfq1OnDjhDBw40LxO/f+p0+j1vaDT6pPT8/Tr1y9VmdKbFg7YqoD+x9dhCoBddCCxLpyns4O02yklXRxv8+bNqcbWAIC3MUYGQIYSExNTzXLRMSI6NiWt5ft1rIjOHsrKIF8AuFi0yADIkF4PSC9NoGvB6ODdDRs2yNSpU83aJXp9Itf6Kzt27DCXBdA1XfSaTzomRK9FBAC5icG+ADKkU4r1AoV6nR5thdGBrrpeTGxsrMcicnrBSR38qouwTZ8+nRADIE/QIgMAAKzFGBkAAGAtggwAALBWUH6YJqpLeutCU95ephwAAOQOHfmiK2jrhVIzugBswAcZDTE6UBEAANhHL+uhK3Xn2yDjuiieVkTJkiV9XRwAAJAFx48fNw0RmV3cNuCDjKs7SUMMQQYAALtkNiyEwb4AAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAawX5ugAAkN9EDFmU6TE7Y6PypCyA7WiRAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAa/lNkImNjZUCBQrIgAED3PsSExOlX79+UqZMGSlevLjceuutcuDAAZ+WEwAA+A+/CDLff/+9vPnmm9KgQQOP/QMHDpSPP/5Y5s6dKytXrpSEhATp1q2bz8oJAAD8i8+DzMmTJ6Vnz57y1ltvySWXXOLef+zYMZk6daqMGTNGWrduLY0bN5a4uDj55ptvZO3atT4tMwAA8A8+DzLadRQVFSVt27b12L9+/Xo5e/asx/7atWtLlSpVZM2aNT4oKQAA8DdBvnzy2bNny4YNG0zXUkr79++X4OBgKVWqlMf+8uXLm/vSk5SUZDaX48ePe7nUAABA8nuLzJ49e+Sxxx6Td999V0JDQ7123piYGAkLC3NvlStX9tq5AQCAf/FZkNGuo4MHD0qjRo0kKCjIbDqgd8KECeZ3bXk5c+aMHD161ONxOmspPDw83fMOHTrUjK9xbRqYAABAYPJZ11KbNm1k8+bNHvv69OljxsE89dRTpiWlcOHCsmzZMjPtWsXHx8vu3bulefPm6Z43JCTEbAAAIPD5LMiUKFFC6tWr57GvWLFiZs0Y1/6+ffvKoEGDpHTp0lKyZEl55JFHTIi59tprfVRqAADgT3w62DczY8eOlYIFC5oWGR3AGxkZKZMmTfJ1sQAAgJ8o4DiOIwFMZy3poF8dL6OtOgDgaxFDFmV6zM7YqDwpC2D797fP15EBAADIKYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsFaQrwsAALaIGLIo02N2xkblSVkA/IMWGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtVhHBkDAY/0XIHDRIgMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALBWkK8LAAAXI2LIooA8j7eea2dsVJ6UBfAVWmQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWj4NMpMnT5YGDRpIyZIlzda8eXNZvHix+/7ExETp16+flClTRooXLy633nqrHDhwwJdFBgAAfsSnQaZSpUoSGxsr69evl3Xr1knr1q2lc+fOsmXLFnP/wIED5eOPP5a5c+fKypUrJSEhQbp16+bLIgMAAD8S5Msn79Spk8ftl156ybTSrF271oScqVOnynvvvWcCjoqLi5Mrr7zS3H/ttdf6qNQAAMBf+M0YmfPnz8vs2bPl1KlTpotJW2nOnj0rbdu2dR9Tu3ZtqVKliqxZs8anZQUAAP7Bpy0yavPmzSa46HgYHQezYMECqVOnjvz4448SHBwspUqV8ji+fPnysn///nTPl5SUZDaX48eP52r5AQBAPg4ytWrVMqHl2LFjMm/ePImOjjbjYXIqJiZGhg8f7tUyAsieiCGLMj1mZ2xUnpQFQGDzedeStrpUr15dGjdubEJIw4YNZfz48RIeHi5nzpyRo0ePehyvs5b0vvQMHTrUhCLXtmfPnjx4FQAAIF8GmZQuXLhguoY02BQuXFiWLVvmvi8+Pl52795tuqLSExIS4p7O7doAAEBg8mnXkraedOjQwQzgPXHihJmhtGLFClm6dKmEhYVJ3759ZdCgQVK6dGkTSB555BETYpixBAAAfB5kDh48KL1795Z9+/aZ4KKL42mIufnmm839Y8eOlYIFC5qF8LSVJjIyUiZNmsT/OQAA4Psgo+vEZCQ0NFQmTpxoNgAAAL8fIwMAAJBVBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2fXqIAQP4VMWRRpsfsjI3Kk7IAsBctMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAA8leQ2b59u/dLAgAAkBdBpnr16tKqVSuZOXOmJCYm5uQUAAAAvllHZsOGDRIXFyeDBg2S/v37S/fu3aVv377StGnTiy8RAOvXfwEAv26Rueqqq2T8+PGSkJAg77zzjuzbt09atmwp9erVkzFjxsihQ4e8X1IAAABvDvYNCgqSbt26ydy5c+WVV16R33//XZ544gmpXLmy9O7d2wQcAAAAvwwy69atk4cfflgqVKhgWmI0xGzbtk0+//xz01rTuXNn75UUAADAG2NkNLToGJn4+Hjp2LGjzJgxw/wsWPCfXFStWjWZNm2aRERE5OT0AAAAuRdkJk+eLPfcc4/cfffdpjUmLeXKlZOpU6fm5PQAAAC5F2S2bt2a6THBwcESHR2dk9MDAADk3hgZ7VbSAb4p6b7p06fn5JQAAAB5E2RiYmKkbNmyaXYnvfzyyzk5JQAAQN4Emd27d5sBvSlVrVrV3AcAAOC3QUZbXjZt2pRq/8aNG6VMmTLeKBcAAEDuBJkePXrIo48+KsuXL5fz58+b7csvv5THHntM7rjjjpycEgAAIG9mLY0YMUJ27twpbdq0Mav7qgsXLpjVfBkjAwAA/DrI6NTq999/3wQa7U4qUqSI1K9f34yRAQAA8Osg41KzZk2zAQAAWBNkdEyMXoJg2bJlcvDgQdOtlJyOlwEAAPDLIKODejXIREVFSb169aRAgQLeLxkAAEBuBJnZs2fLnDlzzIUiAQAArJp+rYN9q1ev7v3SAAAA5HaQefzxx2X8+PHiOE5OHg4AAOC7rqVVq1aZxfAWL14sdevWlcKFC3vcP3/+fO+UDgAAwNtBplSpUtK1a9ecPBQAAMC3QSYuLs57JQAAAMjLMTLq3Llz8sUXX8ibb74pJ06cMPsSEhLk5MmTOT0lAABA7rfI7Nq1S9q3by+7d++WpKQkufnmm6VEiRLyyiuvmNtTpkzJyWkBAF4WMWRRpsfsjI3Kk7IAftMiowviXXPNNfLXX3+Z6yy56LgZXe0XAADAb1tkvv76a/nmm2/MejLJRUREyB9//OGtsgEAAHi/RUavraTXW0pp7969posJAADAb4NMu3btZNy4ce7beq0lHeT7/PPPc9kCAADg311Lr732mkRGRkqdOnUkMTFR7rzzTtm6dauULVtWZs2a5f1SAgAAeCvIVKpUSTZu3GguHrlp0ybTGtO3b1/p2bOnx+BfAAAAvwsy5oFBQXLXXXd5tzQAAAC5HWRmzJiR4f29e/fOyWkB5KKsrCfib2wsMwALgoyuI5Pc2bNn5fTp02Y6dtGiRQkyAADAf2ct6UJ4yTcdIxMfHy8tW7ZksC8AAPD/ay2lVKNGDYmNjU3VWgMAAOD3QcY1AFgvHAkAAOC3Y2Q++ugjj9uO48i+ffvkjTfekBYtWnirbAAAAN4PMl26dPG4rSv7XnrppdK6dWuzWB4AAIDfBhm91hIAAIC1C+IByJt1UnbGRuVJWQAg3wSZQYMGZfnYMWPG5OQpAAAAcifI/PDDD2bThfBq1apl9v32229SqFAhadSokcfYGQAAAL8KMp06dZISJUrI9OnT5ZJLLjH7dGG8Pn36yPXXXy+PP/64t8sJAADgnXVkdGZSTEyMO8Qo/X3kyJHMWgIAAP4dZI4fPy6HDh1KtV/3nThxwhvlAgAAyJ0g07VrV9ONNH/+fNm7d6/ZPvjgA+nbt69069YtJ6cEAADImzEyU6ZMkSeeeELuvPNOM+DXnCgoyASZ0aNH5+SUAAAAeRNkihYtKpMmTTKhZdu2bWbfFVdcIcWKFcvJ6QAAOVhjCMBFXjRSr6+km175WkOMXnMJAADAr4PM4cOHpU2bNlKzZk3p2LGjCTNKu5aYeg0AAPw6yAwcOFAKFy4su3fvNt1MLt27d5clS5Zk+Tw6hbtJkyZmTZpy5cqZi1HGx8d7HJOYmCj9+vWTMmXKSPHixeXWW2+VAwcO5KTYAAAgwOQoyHz22WfyyiuvSKVKlTz2axfTrl27snyelStXmpCydu1a+fzzz83A4Xbt2smpU6c8QtPHH38sc+fONccnJCQwMwoAAOR8sK8GjeQtMS5HjhyRkJCQLJ8nZevNtGnTTMvM+vXr5YYbbpBjx47J1KlT5b333pPWrVubY+Li4uTKK6804efaa6/NSfEBAEB+bpHRyxDMmDHD45pKFy5ckFGjRkmrVq1yXBgNLqp06dLmpwYabaVp27at+5jatWtLlSpVZM2aNTl+HgAAkI9bZDSw6GDfdevWyZkzZ2Tw4MGyZcsW0yKzevXqHBVEg9CAAQOkRYsWUq9ePbNv//79EhwcLKVKlfI4tnz58ua+tCQlJZkt+SrEAAAgMOUoyGjQ0Ktdv/HGG2ag7smTJ824FR3vUqFChRwVRB/7008/yapVq+Ri6ADi4cOHX9Q5ANuw5giA/CrbQUa7etq3b29W9x02bJhXCtG/f3/55JNP5KuvvvIYQBweHm5afI4ePerRKqOzlvS+tAwdOlQGDRrk0SJTuXJlr5QTAABYPkZGp11v2rTJK0+uC+hpiFmwYIF8+eWXUq1aNY/7GzdubJ5v2bJl7n06PVunfTdv3jzNc+pg45IlS3psAAAgMOVosO9dd91lZhNdLO1OmjlzppmVpF1UOu5Ft7///tvcHxYWZhbZ0xaW5cuXm8G/erFKDTHMWAIAADkaI3Pu3Dl555135IsvvjCtJimvsTRmzJgsnWfy5Mnm50033eSxX6dY33333eb3sWPHSsGCBc1CeDqINzIy0lznCQAAIFtBZvv27RIREWEG5TZq1Mjs00G/yelU7KzKyrWZQkNDZeLEiWYDAADIcZDRlXv1ukrazeO6JMGECRPMdGgAAAC/HiOTsgVl8eLFHpcTAAAA8PvBvtnpGgIAAPCLIKPjX1KOgcnOmBgAAACfjZHRFhidTeS6MGRiYqI8+OCDqWYtzZ8/36uFBAAAuOggEx0dnWo9GQAAACuCjK7vAgAAEBCDfQEAAHyJIAMAAKxFkAEAAPnrWksA8k7EkEW+LgIA+C1aZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1mIdGQDI57KyVtHO2Kg8KQuQXbTIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGAtggwAALAWQQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArBXk6wIAAPxfxJBFmR6zMzYqT8oCJEeLDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWqwjA/hw3Q0AwMWhRQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgrSBfFwCwUcSQRb4uAgCAFhkAAGAzggwAALCWT4PMV199JZ06dZKKFStKgQIFZOHChR73O44jzz33nFSoUEGKFCkibdu2la1bt/qsvAAAwL/4NMicOnVKGjZsKBMnTkzz/lGjRsmECRNkypQp8u2330qxYsUkMjJSEhMT87ysAADA//h0sG+HDh3MlhZtjRk3bpw888wz0rlzZ7NvxowZUr58edNyc8cdd+RxaQEAgL/x2zEyO3bskP3795vuJJewsDBp1qyZrFmzxqdlAwAA/sFvp19riFHaApOc3nbdl5akpCSzuRw/fjwXSwkAAHzJb4NMTsXExMjw4cN9XQwAQC6u07QzNipPygL/57ddS+Hh4ebngQMHPPbrbdd9aRk6dKgcO3bMve3ZsyfXywoAAHzDb4NMtWrVTGBZtmyZRzeRzl5q3rx5uo8LCQmRkiVLemwAACAw+bRr6eTJk/L77797DPD98ccfpXTp0lKlShUZMGCAjBw5UmrUqGGCzbPPPmvWnOnSpYsviw0AAPyET4PMunXrpFWrVu7bgwYNMj+jo6Nl2rRpMnjwYLPWzP333y9Hjx6Vli1bypIlSyQ0NNSHpQYAAP7Cp0HmpptuMuvFpEdX+33xxRfNBgAAYM0YGQAAgMwQZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtXx6iQIgr0UMWeTrIgAAvIgWGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtVhHBgCQZ+s07YyNypOyIP+gRQYAAFiLIAMAAKxFkAEAANYiyAAAAGsRZAAAgLUIMgAAwFoEGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAAGCtIF8XAPCWiCGLfF0EAH70731nbFSenQe+Q4sMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBarCMDK7BGDBAYbPy3zFoz/o0WGQAAYC2CDAAAsBZBBgAAWIsgAwAArEWQAQAA1iLIAAAAaxFkAACAtVhHJh/y1poIeXkeAMguPlvyB1pkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWYh2Zi+CtdVQAAPDH75UIPytPWmiRAQAA1iLIAAAAa1kRZCZOnCgRERESGhoqzZo1k++++87XRQIAAH7A74PM+++/L4MGDZLnn39eNmzYIA0bNpTIyEg5ePCgr4sGAAB8zO+DzJgxY+S+++6TPn36SJ06dWTKlClStGhReeedd3xdNAAA4GN+HWTOnDkj69evl7Zt27r3FSxY0Nxes2aNT8sGAAB8z6+nX//5559y/vx5KV++vMd+vf3rr7+m+ZikpCSzuRw7dsz8PH78uNfLdyHpdKbH5Mbz+ku58/I8AODPvPVZ72/fKxd8WB7XeR3HsTfI5ERMTIwMHz481f7KlSv7pDxh48RK3iq3ra8fAPz1s87fPlfDcrk8J06ckLCwMDuDTNmyZaVQoUJy4MABj/16Ozw8PM3HDB061AwOdrlw4YIcOXJEypQpIwUKFBBf0nSpgWrPnj1SsmRJn5bFX1FHmaOOMkcdZQ31lDnqyHd1pC0xGmIqVqyY4XF+HWSCg4OlcePGsmzZMunSpYs7mOjt/v37p/mYkJAQsyVXqlQp8Sf6P5p/EBmjjjJHHWWOOsoa6ilz1JFv6iijlhgrgozS1pXo6Gi55pprpGnTpjJu3Dg5deqUmcUEAADyN78PMt27d5dDhw7Jc889J/v375errrpKlixZkmoAMAAAyH/8Psgo7UZKryvJJtrlpQv7pez6wv+jjjJHHWWOOsoa6ilz1JH/11EBJ7N5TQAAAH7KrxfEAwAAyAhBBgAAWIsgAwAArEWQAQAA1iLIeNnEiRMlIiJCQkNDpVmzZvLdd99leLyui1OrVi0pUqSIWRlx4MCBkpiYKIHqq6++kk6dOpmVGnWl5YULF2b6mBUrVkijRo3MiPjq1avLtGnTJJBlt47mz58vN998s1x66aVmMarmzZvL0qVLJZDl5H3ksnr1agkKCjJLOQSynNSRXqdu2LBhUrVqVfPvTT/L3nnnHQlUOamjd999Vxo2bChFixaVChUqyD333COHDx+WQBUTEyNNmjSREiVKSLly5czitPHx8Zk+bu7cuVK7dm3zXVi/fn359NNPc62MBBkvev/9980CfjoNbcOGDebNHhkZKQcPHkzz+Pfee0+GDBlijv/ll19k6tSp5hxPP/20BCpdzFDrRQNfVuzYsUOioqKkVatW8uOPP8qAAQPk3nvvDegv6uzWkX4Ya5DRDwq9WrzWlX44//DDDxKosltHLkePHpXevXtLmzZtJNDlpI5uv/12s3K6fhbpl9WsWbPMH1qBKrt1pCFY3z99+/aVLVu2mC9r/WP1vvvuk0C1cuVK6devn6xdu1Y+//xzOXv2rLRr187UXXq++eYb6dGjh6kn/RzS8KPbTz/9lDuF1OnX8I6mTZs6/fr1c98+f/68U7FiRScmJibN4/XY1q1be+wbNGiQ06JFCyc/0LffggULMjxm8ODBTt26dT32de/e3YmMjHTyg6zUUVrq1KnjDB8+3MkPslNH+t555plnnOeff95p2LChk19kpY4WL17shIWFOYcPH3byo6zU0ejRo53LL7/cY9+ECROcyy67zMkvDh48aOpq5cqV6R5z++23O1FRUR77mjVr5jzwwAO5UiZaZLzkzJkz5q/htm3buvcVLFjQ3F6zZk2aj7nuuuvMY1zdT9u3bzd/VXfs2DHPyu3vtO6S16nSVq706hT/XI9ML7RWunRpXxfFr8TFxZl/Y9oCitQ++ugjcymYUaNGyWWXXSY1a9aUJ554Qv7++29fF81vaLetXhhRP6c1++gFjOfNm5evPrOPHTtmfmb0+ZLXn9tWrOxrgz///FPOnz+f6tIJevvXX39N8zF33nmneVzLli3NP4pz587Jgw8+GNBdS9mll6VIq071aqv6Aatji+Dp1VdflZMnT5puAvxj69atphv366+/NuNjkJqGvFWrVpkxDQsWLDCfTQ8//LAZ/6EhECItWrQwY2T00jk6llE/s7UbN7tdnDb/kTRgwABTD/Xq1cv257buzw20yPiQDmJ9+eWXZdKkSWZMjQ7aXLRokYwYMcLXRYOldNzV8OHDZc6cOWZgHsT8gaF/NGi9aCsD0v+S0gGv+kWtF+jVVoYxY8bI9OnTaZX5n59//lkee+wxc+0/bU3X6/7t3LnT/AGaH/Tr18+Mc5k9e7b4E/408ZKyZctKoUKFTFNjcno7PDw8zcc8++yz0qtXLzN4VenIbh1Adf/995uZA9o1ld9p3aVVpzo7h9YYT/rhou8lHYCYslk3P9NutnXr1plBh65rtumXtraCauvMZ599Jq1bt5b8TmfgaJdSWFiYe9+VV15p6mnv3r1So0YNye90Bo+2Rjz55JPmdoMGDaRYsWJy/fXXy8iRI00dBqr+/fvLJ598YiYXVKpUKUef2+l9F14svim9JDg4WBo3bmxG/Lvoh6Xe1n7VtJw+fTpVWNEwpLgE1j+07pLXqdKR8+nVaX6ls0v69OljfuosL/w/Db2bN282s95cm/4FrbNx9HddJgH/dJskJCSYbkmX3377zXxGZfbFlV/kx89sx3FMiNHuxi+//FKqVavmf5/buTKEOJ+aPXu2ExIS4kybNs35+eefnfvvv98pVaqUs3//fnN/r169nCFDhriP15kTJUqUcGbNmuVs377d+eyzz5wrrrjCjPgOVCdOnHB++OEHs+nbb8yYMeb3Xbt2mfu1frSeXLReihYt6jz55JPOL7/84kycONEpVKiQs2TJEidQZbeO3n33XScoKMjUzb59+9zb0aNHnUCV3TpKKT/MWspuHenxlSpVcm677TZny5YtZlZKjRo1nHvvvdcJVNmto7i4OPNvbdKkSc62bducVatWOddcc42ZsRqoHnroITObbcWKFR6fL6dPn3Yfk/K7bfXq1aaeXn31VfO5rf/eChcu7GzevDlXykiQ8bLXX3/dqVKlihMcHGze3GvXrnXfd+ONNzrR0dHu22fPnnVeeOEFE15CQ0OdypUrOw8//LDz119/OYFq+fLl5gMj5eaqF/2p9ZTyMVdddZWpU536qB8mgSy7daS/Z3R8IMrJ+yi/BZmc1JF+6bRt29YpUqSICTW6HETyL6xAk5M60unWuryB1lGFChWcnj17Onv37nUClaRRP7ol/xxO+d2m5syZ49SsWdN8busSGosWLcq1Mhb4X0EBAACswxgZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIC1CDIAAMBaBBkAue7uu+82V1ZOubVv397XRQNgOa5+DSBPaGiJi4vz2BcSEpJrz3fmzBlzMVcAgY0WGQB5QkNLeHi4x3bJJZeY+7R15u2335auXbtK0aJFpUaNGvLRRx95PP6nn36SDh06SPHixaV8+fLSq1cv+fPPP93333TTTeYqvQMGDJCyZctKZGSk2a/n0fOFhoZKq1atZPr06eb5jh49KqdOnTJXx543b57Hcy1cuFCKFSsmJ06cyJO6AZBzBBkAfmH48OFy++23y6ZNm6Rjx47Ss2dPOXLkiLlPQ0fr1q3l6quvlnXr1smSJUvkwIED5vjkNKRoK8zq1atlypQpsmPHDrntttukS5cusnHjRnnggQdk2LBh7uM1rNxxxx2pWor0tj6uRIkSefTqAeRYrl2OEgD+R6+MW6hQIadYsWIe20svvWTu14+iZ555xn38yZMnzb7Fixeb2yNGjHDatWvncc49e/aYY+Lj491X4L366qs9jnnqqaecevXqeewbNmyYeZzrKvPffvutKVtCQoK5feDAAScoKMhZsWJFrtQFAO9ijAyAPKHdOpMnT/bYV7p0affvDRo08Ggp0S6fgwcPmtvamrJ8+XLTrZTStm3bpGbNmub3xo0be9wXHx8vTZo08djXtGnTVLfr1q1rWnOGDBkiM2fOlKpVq8oNN9xwUa8XQN4gyADIExpOqlevnu79hQsX9rit41guXLhgfj958qR06tRJXnnllVSPq1Chgsdz5MS9994rEydONEFGu5X69Oljnh+A/yPIAPB7jRo1kg8++EAiIiIkKCjrH1u1atWSTz/91GPf999/n+q4u+66SwYPHiwTJkyQn3/+WaKjo71SbgC5j8G+APJEUlKS7N+/32NLPusoI/369TMDf3v06GGCiHYnLV261LScnD9/Pt3H6eDeX3/9VZ566in57bffZM6cOTJt2jRzX/IWF5091a1bN3nyySelXbt2UqlSJS+8YgB5gSADIE/oTCPtBkq+tWzZMkuPrVixopmJpKFFg0b9+vXNNOtSpUpJwYLpf4xVq1bNTK2eP3++GYOjY3Rcs5ZSrmHTt29fs/bMPffcc5GvFEBeKqAjfvP0GQHAh1566SUzNXvPnj0e+//73//KwIEDJSEhgYX0AIswRgZAQJs0aZKZuVSmTBnTqjN69GizcJ7L6dOnZd++fRIbG2u6oggxgF3oWgIQ0LZu3SqdO3eWOnXqyIgRI+Txxx+XF154wX3/qFGjpHbt2mal4aFDh/q0rACyj64lAABgLVpkAACAtQgyAADAWgQZAABgLYIMAACwFkEGAABYiyADAACsRZABAADWIsgAAABrEWQAAIDY6v8AmmWnYkoRNSAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "energy_scores = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "        images, _, _, = data[0].to(device), data[1].to(device), data[3].to(device)\n",
    "        super_outputs, sub_outputs = model(images)\n",
    "        energy = torch.logsumexp(super_outputs, dim=1)\n",
    "        energy_scores.extend(energy.cpu().numpy())\n",
    "\n",
    "plt.hist(energy_scores, bins=50)\n",
    "plt.title(\"Energy distribution\")\n",
    "plt.xlabel(\"Energy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 1.9949\n",
      "Validation loss: 0.998\n",
      "Val Superclass Acc: 99.20%\n",
      "Val Subclass Acc: 75.96%\n",
      "\n",
      "Epoch 2\n",
      "Train Loss: 0.7351\n",
      "Validation loss: 0.691\n",
      "Val Superclass Acc: 99.04%\n",
      "Val Subclass Acc: 82.64%\n",
      "\n",
      "Epoch 3\n",
      "Train Loss: 0.5639\n",
      "Validation loss: 0.621\n",
      "Val Superclass Acc: 99.52%\n",
      "Val Subclass Acc: 80.73%\n",
      "\n",
      "Epoch 4\n",
      "Train Loss: 0.4811\n",
      "Validation loss: 0.639\n",
      "Val Superclass Acc: 99.20%\n",
      "Val Subclass Acc: 79.14%\n",
      "\n",
      "Epoch 5\n",
      "Train Loss: 0.4429\n",
      "Validation loss: 0.493\n",
      "Val Superclass Acc: 99.68%\n",
      "Val Subclass Acc: 85.51%\n",
      "\n",
      "Epoch 6\n",
      "Train Loss: 0.4028\n",
      "Validation loss: 0.527\n",
      "Val Superclass Acc: 99.68%\n",
      "Val Subclass Acc: 84.71%\n",
      "\n",
      "Epoch 7\n",
      "Train Loss: 0.3878\n",
      "Validation loss: 0.513\n",
      "Val Superclass Acc: 99.04%\n",
      "Val Subclass Acc: 83.76%\n",
      "\n",
      "Epoch 8\n",
      "Train Loss: 0.3460\n",
      "Validation loss: 0.475\n",
      "Val Superclass Acc: 99.36%\n",
      "Val Subclass Acc: 85.99%\n",
      "\n",
      "Epoch 9\n",
      "Train Loss: 0.3444\n",
      "Validation loss: 0.496\n",
      "Val Superclass Acc: 99.36%\n",
      "Val Subclass Acc: 85.35%\n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.3154\n",
      "Validation loss: 0.516\n",
      "Val Superclass Acc: 99.20%\n",
      "Val Subclass Acc: 85.67%\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    trainer.train_epoch()\n",
    "    trainer.validate_epoch(energy_threshold_super=1.2, energy_threshold_sub=1.3)\n",
    "\n",
    "    print('')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test predictions saved to example_test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "test_predictions = trainer.test(save_to_csv=True, return_predictions=True, energy_threshold_super=1.2, energy_threshold_sub=1.3)\n",
    "print(\"\\nTest predictions saved to example_test_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nndl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
